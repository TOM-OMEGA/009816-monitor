import os
import requests
import json
import time
from datetime import datetime

# === AI å†·å» / Cache ===
AI_CACHE = {}
AI_LAST_CALL = {}
AI_COOLDOWN_MINUTES = 1

def get_ai_point(target_name, strategy_type, extra_data):
    """
    é€šç”¨ AI åˆ¤æ–·å‡½å¼ (æ”¯æ´ä¸‰ç¨®ç­–ç•¥åˆ†æµ)
    """
    global AI_CACHE, AI_LAST_CALL
    now = datetime.now()
    
    # å»ºç«‹ Cache Key
    key = f"{target_name}_{strategy_type}_{now.strftime('%H%M')}"

    # 1. æª¢æŸ¥ Cache
    if key in AI_CACHE:
        return AI_CACHE[key]

    # 2. æª¢æŸ¥ API Key
    gemini_key = os.environ.get("GEMINI_API_KEY")
    if not gemini_key:
        return {"decision": "ERROR", "confidence": 0, "reason": "å°šæœªè¨­å®š GEMINI_API_KEY", "status": "ç³»çµ±ç•°å¸¸"}

    # ==========================================
    # ğŸ§  ç­–ç•¥åˆ†æµèˆ‡ç‹€æ…‹ç¯„æœ¬è¨­å®š
    # ==========================================
    prompt_context = ""
    status_template = ""
    
    if strategy_type == "stock_audit":
        d = extra_data
        status_template = "AI ç‹€æ…‹ï¼šè¤‡åˆ©è¨ˆç®—ä¸­ ğŸ¤–\nğŸ’¡ æé†’ï¼šè¤‡åˆ©æ•ˆæœç©©å®šï¼Œå·²ç´å…¥ 2027 æŠ•å½±è¨ˆç•«ã€‚"
        prompt_context = f"""
ä½ æ˜¯ä¸€ä½é•·æœŸåƒ¹å€¼æŠ•è³‡ç¶“ç†äººï¼Œè«‹è©•ä¼° "{target_name}" çš„å­˜è‚¡åƒ¹å€¼ã€‚
ã€é—œéµæ•¸æ“šã€‘
- ç›®å‰è‚¡åƒ¹: {d.get('price')}
- 2027å¹´æŠ•å½±ç›®æ¨™åƒ¹: {d.get('projected_1y')}
- ç³»çµ±ç¶œåˆè©•åˆ†: {d.get('score')} / 100
- è·é›¢ç™¼è¡Œåƒ¹: {d.get('dist')}%
ã€æŒ‡ä»¤ã€‘åˆ¤æ–·å®‰å…¨é‚Šéš›ï¼Œçµ¦å‡ºè²·é€²/æŒæœ‰/è§€æœ›å»ºè­°ã€‚"""

    elif strategy_type == "grid_trading":
        d = extra_data
        status_template = "AI ç‹€æ…‹ï¼šç¶²æ ¼ç›£æ§ä¸­ ğŸ“‰\nğŸ’¡ æé†’ï¼šåš´å®ˆå‹•æ…‹é–“è·ï¼Œé¿å…æƒ…ç·’åŒ–æ‰‹å‹•äº¤æ˜“ã€‚"
        prompt_context = f"""
ä½ æ˜¯ä¸€ä½é«˜é »ç¶²æ ¼äº¤æ˜“å“¡ï¼Œè«‹è©•ä¼° "{target_name}" çš„çŸ­ç·šæ³¢å‹•æ©Ÿæœƒã€‚
ã€é—œéµæ•¸æ“šã€‘
- ç¾åƒ¹: {d.get('price')}
- çŸ­ç·šè¶¨å‹¢: {d.get('trend')}
- RSI (14): {d.get('rsi')}
- å¸ƒæ—ä¸‹ç·£ (è£œå€‰é»): {d.get('grid_buy')}
ã€æŒ‡ä»¤ã€‘é‡å°æ˜¯å¦åŸ·è¡Œç¶²æ ¼è£œå€‰çµ¦å‡ºå»ºè­°ã€‚"""

    elif strategy_type == "us_market":
        status_template = "AI ç‹€æ…‹ï¼šå…¨çƒè¯å‹•åˆ†æä¸­ ğŸŒ\nğŸ’¡ æé†’ï¼šç§‘æŠ€è‚¡æ³¢å‹•åŠ‡çƒˆï¼Œæ³¨æ„ TSM æº¢åƒ¹é¢¨éšªã€‚"
        prompt_context = f"""
ä½ æ˜¯ä¸€ä½å®è§€å¸‚å ´åˆ†æå¸«ï¼Œè«‹è§£è®€ä»¥ä¸‹ç¾è‚¡æ•¸æ“šä¸¦é æ¸¬æ˜æ—¥å°è‚¡é–‹ç›¤æ°£æ°›ã€‚
ã€å¸‚å ´æ‘˜è¦ã€‘
{extra_data}
ã€æŒ‡ä»¤ã€‘çµ¦å‡ºå°å°è‚¡æŠ•è³‡äººçš„æ“ä½œæé†’ã€‚"""

    # åŠ ä¸Šçµ±ä¸€çš„ JSON è¼¸å‡ºè¦æ±‚ (åŒ…å« status æ¬„ä½)
    prompt = f"""
{prompt_context}

âš ï¸ åš´æ ¼è¼¸å‡º JSON æ ¼å¼ï¼Œä¸è¦æœ‰ Markdownï¼Œä¸è¦æœ‰å¤šé¤˜æ–‡å­—ï¼š
{{
  "decision": "æ±ºç­–çµæœ",
  "confidence": 0-100,
  "reason": "50å­—å…§ç†ç”±",
  "status": "{status_template}"
}}
"""

    payload = {
        "contents": [{"parts": [{"text": prompt}]}], 
        "generationConfig": {"temperature": 0.3}
    }

    # 4. å‘¼å« API + å¼·åŒ–é‡è©¦æ©Ÿåˆ¶
    ai_result = {"decision": "è§€æœ›", "confidence": 0, "reason": "AI é€£ç·šé€¾æ™‚", "status": status_template}
    
    for attempt in range(3):
        try:
            api_url = f"https://generativelanguage.googleapis.com/v1/models/gemini-2.0-flash:generateContent?key={gemini_key}"
            res = requests.post(api_url, json=payload, timeout=30)

            if res.status_code == 429:
                wait_time = 25 + (attempt * 5)
                time.sleep(wait_time)
                continue

            res.raise_for_status()
            data = res.json()

            text = data["candidates"][0]["content"]["parts"][0]["text"]
            clean_text = text.replace("```json", "").replace("```", "").strip()
            ai_result = json.loads(clean_text)
            break 

        except Exception as e:
            if attempt < 2:
                time.sleep(5)
                continue
            ai_result = {"decision": "ERROR", "confidence": 0, "reason": f"ç•°å¸¸: {str(e)[:20]}", "status": status_template}

    AI_CACHE[key] = ai_result
    return ai_result
